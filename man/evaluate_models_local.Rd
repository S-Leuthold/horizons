% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluation-local.R
\name{evaluate_models_local}
\alias{evaluate_models_local}
\title{Evaluate Model Configurations on Local Machines}
\usage{
evaluate_models_local(
  config,
  input_data,
  covariate_data = NULL,
  variable,
  output_dir = NULL,
  grid_size = 10,
  bayesian_iter = 15,
  cv_folds = 10,
  allow_par = TRUE,
  n_cv_cores = NULL,
  prune_models = TRUE,
  prune_threshold = 0.9,
  seed = 307,
  resume = TRUE,
  verbose = TRUE
)
}
\arguments{
\item{config}{\verb{[data.frame]} Configuration grid with required columns:
\itemize{
\item \code{model}: Model type (e.g., "random_forest", "cubist", "xgboost")
\item \code{preprocessing}: Spectral preprocessing method
\item \code{transformation}: Response transformation method
\item \code{feature_selection}: Feature selection approach
\item \code{covariates}: (Optional) List column of covariate names
}}

\item{input_data}{\verb{[data.frame]} Preprocessed spectral data with columns:
\itemize{
\item \code{Sample_ID}: Unique sample identifiers
\item \code{Response}: Target variable (will be renamed from variable param)
\item Numeric columns: Wavenumbers (e.g., \code{"600"}, \code{"602"}, \code{"604"})
}}

\item{covariate_data}{\verb{[data.frame]} (Optional) Predicted covariate data with \code{Sample_ID}
and covariate columns. Default: \code{NULL}.}

\item{variable}{\verb{[character]} Name of response variable column in input_data.}

\item{output_dir}{\verb{[character]} (Optional) Output directory path.
Default: Auto-generated with timestamp.}

\item{grid_size}{\verb{[integer]} Grid search combinations per model. Default: \code{10}.}

\item{bayesian_iter}{\verb{[integer]} Bayesian optimization iterations. Default: \code{15}.}

\item{cv_folds}{\verb{[integer]} Cross-validation folds. Default: \code{10}.}

\item{allow_par}{\verb{[logical]} Use parallel processing for CV? Default: \code{TRUE}. Uses future::plan(multisession) for local runs.}

\item{n_cv_cores}{\verb{[integer]} (Optional) Cores for parallel CV.
Default: \code{parallel::detectCores() - 2}.}

\item{prune_models}{\verb{[logical]} Prune models that don't beat baseline? Default: \code{TRUE}.}

\item{prune_threshold}{\verb{[numeric]} Performance threshold vs baseline (0-1). Default: \code{0.9}.}

\item{seed}{\verb{[integer]} Random seed for reproducibility. Default: \code{307}.}

\item{resume}{\verb{[logical]} Resume from existing checkpoint files? Default: \code{TRUE}.}

\item{verbose}{\verb{[logical]} Print progress messages? Default: \code{TRUE}.}
}
\value{
A \verb{[tibble]} with evaluation results containing:
\itemize{
\item \code{config_id}: Configuration identifier (e.g., "001_rf_Log_SNV_PCA_ph")
\item \code{workflow_id}: Human-readable model description
\item \code{model}, \code{preprocessing}, \code{transformation}, \code{feature_selection}: Configuration details
\item \code{covariates}: List column of covariate names used
\item \code{rsq}, \code{rmse}, \code{rrmse}, \code{ccc}, \code{rpd}, \code{mae}: Performance metrics on test set
\item \code{status}: Result status ("success", "failed", "pruned")
\item \code{elapsed_secs}: Total computation time per model
\item \code{best_params}: List column with optimal hyperparameters
\item \code{error_message}: Error details for failed models
}
}
\description{
Executes comprehensive model evaluation workflows locally with sequential model processing
and optional parallel cross-validation. This is the primary entry point for desktop and
server-based model comparison outside of HPC environments, providing automated hyperparameter
tuning, checkpointing, and performance tracking.
}
\section{Details}{

The evaluation pipeline executes these stages for each configuration:
\enumerate{
\item \strong{Recipe building}: Applies spectral preprocessing and feature selection
\item \strong{Model specification}: Defines model with tunable hyperparameters
\item \strong{Grid search}: Latin hypercube sampling across parameter space
\item \strong{Bayesian optimization}: Refines best grid search results
\item \strong{Final fitting}: Trains on full training set, evaluates on test set
\item \strong{Checkpointing}: Saves results for resume capability
}

Models are processed sequentially to avoid memory issues with large spectral datasets.
Cross-validation within each model can be parallelized for faster tuning.
}

\section{Warning}{

\itemize{
\item Memory usage scales with spectral data size and number of features
\item Large configuration grids (>100 models) may require hours to complete
\item Parallel CV may conflict with system-level parallelization
\item Results depend on random seed for reproducible comparisons
}
}

\examples{
# Basic evaluation workflow
configs <- create_configs(models = c("random_forest", "cubist"))

evaluate_models_local(config      = configs,
                      input_data  = spectral_data,
                      variable    = "SOC",
                      grid_size   = 5,
                      verbose     = TRUE) -> results

# With covariates and custom settings
evaluate_models_local(config           = extended_configs,
                      input_data       = preprocessed_spectra,
                      covariate_data   = climate_data,
                      variable         = "clay",
                      bayesian_iter    = 20,
                      prune_threshold  = 0.8,
                      n_cv_cores       = 4) -> detailed_results

\dontrun{
# Large-scale evaluation with error handling
safely_execute(expr = {
  evaluate_models_local(config      = full_config_grid,
                        input_data  = large_dataset,
                        variable    = "SOC",
                        allow_par   = TRUE,
                        verbose     = TRUE)
},
default_value = NULL,
error_message = "Model evaluation failed") -> eval_safe

results <- eval_safe$result
}

}
\seealso{
\itemize{
\item \code{\link[=evaluate_models_hpc]{evaluate_models_hpc()}} for HPC cluster evaluation
\item \code{\link[=create_configs]{create_configs()}} to generate configuration grids
\item \code{\link[=finalize_top_workflows]{finalize_top_workflows()}} for ensemble model creation
\item \code{vignette("model-evaluation")} for complete workflow guide
}
}
