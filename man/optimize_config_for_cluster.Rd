% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/library-train.R
\name{optimize_config_for_cluster}
\alias{optimize_config_for_cluster}
\title{Optimize Model Config for Cluster}
\usage{
optimize_config_for_cluster(
  cluster_splits,
  property,
  n_configs_test = 10,
  config_subset_prop = 0.2,
  quick_grid_size = 5,
  final_grid_size = 10,
  quick_cv_folds = 3,
  final_cv_folds = 10,
  allow_par = TRUE,
  n_workers = 4,
  seed = 123,
  verbose = TRUE
)
}
\arguments{
\item{cluster_splits}{List from prepare_cluster_splits() with training_pool and external_test}

\item{property}{Character. Property name}

\item{n_configs_test}{Integer. How many top configs to test. Default: 10}

\item{config_subset_prop}{Numeric (0-1). Proportion of training pool for config testing. Default: 0.2}

\item{quick_grid_size}{Integer. Grid points for config testing. Default: 5}

\item{final_grid_size}{Integer. Grid points for final tuning. Default: 10}

\item{quick_cv_folds}{Integer. CV folds for config testing. Default: 3}

\item{final_cv_folds}{Integer. CV folds for final tuning. Default: 10}

\item{seed}{Integer. Random seed. Default: 123}

\item{verbose}{Logical. Print progress? Default: TRUE}
}
\value{
List with:
\describe{
\item{final_workflow}{Trained and butchered workflow (ready for prediction)}
\item{winning_config}{Tibble row from OPTIMAL_CONFIGS with winner details}
\item{config_scores}{Tibble with all tested configs and their scores}
\item{best_params}{List with optimal hyperparameters}
\item{external_test}{Tibble with held-out test set (for UQ calibration)}
\item{training_time_sec}{Numeric, total time for optimization + training}
}

Returns NULL if optimization or training fails.
}
\description{
Tests multiple model configurations on a cluster's training data, ranks by
composite score, and trains the winning config with full hyperparameter tuning.
Implements two-stage optimization: fast config selection, then deep tuning.
}
\details{
\strong{Two-Stage Training:}

\strong{Stage 1 - Config Selection (Fast):}
\enumerate{
\item Take top 10 configs from OPTIMAL_CONFIGS_V1 for this property
\item Subset training pool to 20\% (~380 samples for quick testing)
\item For each config:
\itemize{
\item Build recipe (preprocessing + feature selection)
\item Define model spec
\item Quick tune: 5 grid points, 3-fold CV
\item Evaluate: RPD, CCC, RÂ², RMSE on validation fold
\item Calculate composite score
\item DISCARD model (don't save)
}
\item Rank by composite score
\item Select winner (highest score)
}

\strong{Stage 2 - Hyperparameter Tuning (Thorough):}
\enumerate{
\item Take winning config
\item Use FULL 80\% training pool (~1,930 samples)
\item Build recipe + model spec
\item Full tune: 10 grid points, 10-fold CV (parallel CV folds)
\item Fit final model with best hyperparameters
\item butcher::butcher() for memory
\item Return trained workflow
}

\strong{Memory Discipline:}
\itemize{
\item Stage 1: Test 10 configs, rm() all after scoring
\item Stage 2: Keep only final butchered workflow
\item Target: <500MB overhead
}
}
\keyword{internal}
