% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluation-fit_parallel.R
\name{evaluate_model_fit_parallel}
\alias{evaluate_model_fit_parallel}
\title{Evaluate Model Configuration with Fit-Level Parallelization}
\usage{
evaluate_model_fit_parallel(
  config_row,
  input_data,
  covariate_data = NULL,
  variable,
  row_index,
  output_dir,
  n_workers = NULL,
  grid_size = 10,
  bayesian_iter = 15,
  cv_folds = 5,
  pruning = TRUE,
  save_output = FALSE,
  verbose = TRUE
)
}
\arguments{
\item{config_row}{A single-row tibble containing model configuration. Must include:
\code{model}, \code{transformation}, \code{preprocessing}, \code{feature_selection}, \code{covariates}, \code{include_covariates}}

\item{input_data}{A tibble with preprocessed spectral data including \code{Sample_ID},
wavenumber columns, and the target response variable}

\item{covariate_data}{Optional tibble of predicted covariates matched by \code{Sample_ID}}

\item{variable}{Character. Name of the response variable to predict}

\item{row_index}{Integer. Row index in the configuration grid for labeling}

\item{output_dir}{Character. Directory path for saving outputs and logs}

\item{n_workers}{Integer. Number of parallel workers to use (default = NULL, auto-detect)}

\item{grid_size}{Integer. Number of grid search candidates (default = 10)}

\item{bayesian_iter}{Integer. Number of Bayesian optimization iterations (default = 15)}

\item{cv_folds}{Integer. Number of cross-validation folds (default = 5)}

\item{pruning}{Logical. Enable early pruning of poor models (default = TRUE)}

\item{save_output}{Logical. Save full model output to disk (default = FALSE)}

\item{verbose}{Logical. Print detailed progress messages (default = TRUE)}
}
\value{
A list containing:
\itemize{
\item \strong{status_summary}: One-row tibble with metrics and status
\item \strong{saved_path}: Path to saved model file (if save_output = TRUE)
\item \strong{timing_info}: Detailed timing for each phase
\item \strong{memory_info}: Memory usage statistics
}
}
\description{
Evaluates a single model configuration with parallel tuning operations optimized
for HPC environments. This function handles the actual model fitting with
parallelization at the tuning level (grid search and Bayesian optimization)
rather than at the model level.

Key features:
\itemize{
\item Parallel grid search across hyperparameter combinations
\item Parallel Bayesian optimization across CV folds
\item Automatic worker allocation based on task requirements
\item Memory-efficient processing with minimal overhead
\item Comprehensive error handling and recovery
}
}
\details{
\subsection{Parallelization Strategy}{

The function implements intelligent parallelization:

\strong{Grid Search Phase}:
\itemize{
\item Parallelizes across hyperparameter combinations
\item Each worker evaluates one combination across all CV folds
\item Uses work-stealing for automatic load balancing
}

\strong{Bayesian Optimization Phase}:
\itemize{
\item Parallelizes across CV folds within each iteration
\item Sequential iterations (each builds on previous results)
\item Typically uses fewer workers (limited by CV folds)
}

\strong{Final Fitting}:
\itemize{
\item Sequential fitting of best model on full training set
\item Evaluation on holdout test set
}
}

\subsection{Memory Management}{
\itemize{
\item Lightweight garbage collection between phases
\item Efficient data passing to workers
\item Automatic cleanup of temporary objects
}
}
}
\examples{
\dontrun{
result <- evaluate_model_fit_parallel(
  config_row     = config[1, ],
  input_data     = spectral_data,
  covariate_data = predicted_covs,
  variable       = "MAOM_C_g_kg",
  row_index      = 1,
  output_dir     = "outputs",
  n_workers      = 50
)
}

}
\seealso{
\code{\link{run_hpc_evaluation}}, \code{\link{manage_worker_pool}},
\code{\link{evaluate_model_config}}
}
