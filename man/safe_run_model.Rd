% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluation-safely_run_single_evaluation.R
\name{safe_run_model}
\alias{safe_run_model}
\title{Safely Run a Single Model Configuration and Log Results}
\usage{
safe_run_model(
  config_row,
  input_data,
  covariate_data,
  variable,
  row_index,
  output_dir,
  grid_size = 10,
  bayesian_iter = 15,
  cv_folds = 5,
  pruning = TRUE,
  save_output = FALSE
)
}
\arguments{
\item{config_row}{A single-row tibble with configuration details. Must contain:
\code{model}, \code{transformation}, \code{preprocessing}, \code{covariates}, and \code{include_covariates}.}

\item{input_data}{A preprocessed tibble of spectral data with \code{Sample_ID}, \code{Wavenumber}, and \code{Absorbance}.}

\item{covariate_data}{Optional tibble of predicted covariates (if \code{include_covariates = TRUE}).}

\item{variable}{Character name of the outcome variable to predict.}

\item{row_index}{Integer indicating the row number (used for logging and filenames).}

\item{output_dir}{Directory for saving pruned results and error logs.}

\item{grid_size}{Number of grid search candidates per model (default = 10).}

\item{bayesian_iter}{Number of Bayesian tuning iterations (default = 15).}

\item{cv_folds}{Number of cross-validation folds (default = 5).}
}
\value{
A named list with:
\describe{
\item{status_summary}{A one-row tibble with model ID, RMSE, RÂ², pruned file path, error path, error message, and status flag.}
\item{pruned_output_path}{Path to \code{.qs} file with pruned model result (if successful).}
}
}
\description{
Executes a full ensemble model evaluation for a single configuration row,
with error handling, output pruning, and structured logging. Intended for
internal use within batch modeling workflows. Wraps \code{full_model_evaluation()}
and saves output summaries for downstream stacking and diagnostics.
}
\details{
This function is designed for internal use in \code{run_batch_models()}, where it is
called iteratively across a grid of model configurations. The returned summary row
supports monitoring and downstream filtering, while pruned results retain key
evaluation metrics and stacking-ready workflows.

Errors are caught and written to \code{.json} files in the specified \code{output_dir}.
CLI progress messages are displayed throughout the run.
}
\seealso{
\code{\link[=full_model_evaluation]{full_model_evaluation()}}, \code{\link[=prune_model_output]{prune_model_output()}}, \code{\link[=run_batch_models]{run_batch_models()}}
}
\keyword{internal}
