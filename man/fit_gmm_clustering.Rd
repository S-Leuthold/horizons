% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/library-clustering.R
\name{fit_gmm_clustering}
\alias{fit_gmm_clustering}
\title{Fit GMM Clustering on Library PCA Scores}
\usage{
fit_gmm_clustering(
  pca_scores,
  k_range = c(5, 7, 9, 11),
  covariance_regularization = TRUE,
  min_cluster_size = 300,
  seed = 123,
  verbose = TRUE
)
}
\arguments{
\item{pca_scores}{Matrix of PCA scores (n_samples × n_components)}

\item{k_range}{Integer vector. Cluster counts to test. Default: c(5, 7, 9, 11)}

\item{covariance_regularization}{Logical. Apply Ledoit-Wolf shrinkage? Default: TRUE}

\item{min_cluster_size}{Integer. Minimum samples per cluster. Default: 300}

\item{seed}{Integer. Random seed for reproducibility. Default: 123}

\item{verbose}{Logical. Print progress? Default: TRUE}
}
\value{
List with:
\describe{
\item{model}{Full mclust::Mclust object (for predict() method)}
\item{n_clusters}{Integer, optimal K selected by BIC}
\item{bic_values}{Numeric vector, BIC for each K tested}
\item{cluster_assignments}{Integer vector, cluster ID for each sample}
\item{cluster_sizes}{Named integer vector, sample count per cluster}
\item{centroids}{Matrix, cluster centers in PCA space}
\item{covariances}{Array, regularized covariance matrices per cluster}
}

Returns NULL if fitting fails.
}
\description{
Trains Gaussian Mixture Model on library PCA scores with automatic K selection
via BIC. Applies covariance regularization (Ledoit-Wolf shrinkage) to prevent
singularity and enforces minimum cluster sizes for robust model training.
}
\details{
\strong{Algorithm:}
\enumerate{
\item Test K ∈ k_range using mclust::Mclust()
\item Select optimal K via BIC (Bayesian Information Criterion)
\item Apply Ledoit-Wolf shrinkage to cluster covariances if enabled
\item Check minimum cluster size constraint
\item Merge small clusters or refit if needed
\item Return full mclust object + metadata
}

\strong{BIC Selection:}
Lower BIC = better fit. mclust tests different covariance structures
(VVV = full covariance, EII = spherical, etc.) and selects best.

\strong{Covariance Regularization:}
For high-dimensional PCA spaces (15-25 components), empirical covariances
can be unstable. Ledoit-Wolf shrinkage regularizes toward diagonal:
Σ_reg = λ * Σ_sample + (1-λ) * Σ_diagonal

This prevents singularity when computing Mahalanobis distances.
}
\section{Performance}{

\itemize{
\item ~30 seconds for 12K samples, 20 components, testing 4 K values
\item Memory: ~200-300MB during fitting
\item Final object: ~10-20MB
}
}

\examples{
\dontrun{
# Fit GMM on library PCA scores
pca_result <- horizons:::perform_pca_on_library(preprocessed_data)
gmm_result <- horizons:::fit_gmm_clustering(
  pca_scores = pca_result$pca_scores,
  k_range = c(5, 7, 9),
  verbose = TRUE
)
}

}
\seealso{
\code{\link[=assign_to_clusters]{assign_to_clusters()}}, \code{\link[=compute_ad_thresholds]{compute_ad_thresholds()}}
}
\keyword{internal}
