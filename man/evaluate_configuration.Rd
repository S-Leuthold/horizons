% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluation-core.R
\name{evaluate_configuration}
\alias{evaluate_configuration}
\title{Evaluate a Single Model Configuration}
\usage{
evaluate_configuration(
  config_row,
  input_data,
  data_split,
  config_id,
  covariate_data = NULL,
  variable,
  output_dir = NULL,
  grid_size = 10,
  bayesian_iter = 15,
  cv_folds = 10,
  parallel_cv = TRUE,
  n_cv_cores = NULL,
  prune_models = FALSE,
  prune_threshold = 0.9,
  seed = 307
)
}
\arguments{
\item{config_row}{Single-row data frame or tibble containing model configuration with columns:
\itemize{
\item \code{model}: Character. Model type (e.g., "random_forest", "cubist", "xgboost")
\item \code{transformation}: Character. Response transformation (e.g., "Log Transformation")
\item \code{preprocessing}: Character. Spectral preprocessing (e.g., "snv", "raw")
\item \code{feature_selection}: Character. Feature selection method (e.g., "pca", "none")
\item \code{covariates}: List column or NULL. Covariate names to include
}}

\item{input_data}{Data frame containing full dataset with spectral features and response.
Used for recipe preparation and preprocessing steps.}

\item{data_split}{An \code{rsplit} object from rsample package defining train/test split.
Ensures consistent data partitioning across all model configurations.}

\item{config_id}{Character or numeric. Unique identifier for this configuration,
used in progress messages and error reporting.}

\item{covariate_data}{Optional data frame containing covariate predictions.
Must have same row ordering as \code{input_data}. NULL if no covariates.}

\item{variable}{Character. Name of response variable column in \code{input_data}.}

\item{output_dir}{Character path to directory for saving outputs (checkpoints, logs).
NULL skips file output.}

\item{grid_size}{Integer. Number of hyperparameter combinations for initial grid search.
Uses Latin hypercube sampling for better parameter space coverage. Default: 10.}

\item{bayesian_iter}{Integer. Number of Bayesian optimization iterations after grid search.
Set to 0 to skip Bayesian optimization. Default: 15.}

\item{cv_folds}{Integer. Number of cross-validation folds for hyperparameter tuning.
Minimum 2, recommended 5-10. Uses stratified sampling on response. Default: 10.}

\item{parallel_cv}{Logical. Enable parallel processing for cross-validation folds.
Uses future package for cross-platform parallel processing. Default: TRUE.}

\item{n_cv_cores}{Integer or NULL. Number of cores for parallel CV.
NULL auto-detects (total cores - 2). Ignored if parallel_cv = FALSE.}

\item{prune_models}{Logical. Skip Bayesian optimization for models that don't beat
baseline (mean predictor) by required margin. Saves computation. Default: FALSE.}

\item{prune_threshold}{Numeric between 0 and 1. Multiplier for baseline RRMSE.
Model must achieve RRMSE < baseline_RRMSE * threshold to proceed to Bayesian.
Example: 0.9 = must beat baseline by 10\%. Default: 0.9.}

\item{seed}{Integer. Random seed for reproducibility of CV splits and tuning. Default: 123.}
}
\value{
A single-row tibble containing:
\describe{
\item{config_id}{Configuration identifier}
\item{workflow_id}{Unique workflow identifier string}
\item{model}{Model type used}
\item{transformation}{Response transformation applied}
\item{preprocessing}{Spectral preprocessing method}
\item{feature_selection}{Feature selection method}
\item{covariates}{Concatenated covariate names or NA}
\item{rsq}{R-squared on test set}
\item{rmse}{Root mean squared error on test set}
\item{rrmse}{Relative RMSE as percentage}
\item{rpd}{Ratio of performance to deviation}
\item{ccc}{Lin's concordance correlation coefficient}
\item{mae}{Mean absolute error on test set}
\item{grid_seconds}{Time for grid search in seconds}
\item{bayes_seconds}{Time for Bayesian optimization in seconds}
\item{total_seconds}{Total execution time in seconds}
\item{status}{"success", "failed", or "pruned"}
\item{error_message}{Error description if failed, NA otherwise}
\item{fitted_workflow}{List column with fitted workflow object for stacking}
}
}
\description{
Core function for evaluating a single model configuration.
Implements a complete modeling pipeline: recipe building → model specification →
hyperparameter tuning (grid + Bayesian) → final evaluation on test set.
Designed for sequential model evaluation with optional parallel cross-validation.
}
\details{
The function executes the following pipeline:
\enumerate{
\item Input validation and configuration extraction
\item Recipe building with specified preprocessing and feature selection
\item Model specification from configuration
\item Workflow creation (recipe + model)
\item Cross-validation split generation (stratified on response)
\item Optional parallel backend setup (OS-aware)
\item Grid search with Latin hypercube sampling
\item Aggressive memory cleanup after grid search
\item Optional pruning based on baseline comparison
\item Bayesian optimization (if not pruned) with early stopping
\item Final model fit on full training set
\item Test set evaluation with comprehensive metrics
}

Baseline comparison for pruning uses RMSE of mean predictor. Models must beat
baseline * threshold to proceed to Bayesian optimization.

All errors are caught and returned as failed results with descriptive messages,
ensuring batch evaluation continues even if individual models fail.
}
\examples{
\dontrun{
# Create configuration
config <- tibble::tibble(
  model = "random_forest",
  transformation = "Log Transformation",
  preprocessing = "snv",
  feature_selection = "pca",
  covariates = list(c("clay", "sand"))
)

# Create train/test split
split <- rsample::initial_split(spectral_data, prop = 0.8)

# Evaluate single model
result <- evaluate_single_model_local(
  config_row = config[1, ],
  input_data = spectral_data,
  data_split = split,
  config_id = "RF_001",
  variable = "SOC",
  parallel_cv = TRUE,
  prune_models = TRUE
)
}

}
\seealso{
\code{\link{build_recipe}} for recipe construction details
\code{\link{define_model_specifications}} for supported model types
\code{\link{rrmse}}, \code{\link{rpd}}, \code{\link{ccc}} for custom metrics
}
\keyword{internal}
