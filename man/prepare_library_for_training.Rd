% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/library-core.R
\name{prepare_library_for_training}
\alias{prepare_library_for_training}
\title{Library Prediction Core Orchestrator}
\usage{
prepare_library_for_training(
  property,
  k_range = c(5, 7, 9, 11),
  variance_threshold = 0.99,
  remove_water_bands = FALSE,
  min_cluster_size = 300,
  max_samples = NULL,
  cache_dir = NULL,
  seed = 123,
  verbose = TRUE
)
}
\arguments{
\item{property}{Character. Property from LIBRARY_PROPERTIES}

\item{k_range}{Integer vector. Cluster range for BIC. Default: c(5, 7, 9, 11)}

\item{variance_threshold}{Numeric. PCA variance to retain. Default: 0.99}

\item{remove_water_bands}{Logical. Experimental water band removal. Default: FALSE}

\item{min_cluster_size}{Integer. Minimum samples per cluster. Default: 300}

\item{max_samples}{Integer. For testing. Default: NULL (all)}

\item{cache_dir}{Character. Cache directory. Default: NULL}

\item{seed}{Integer. Random seed. Default: 123}

\item{verbose}{Logical. Print progress? Default: TRUE}
}
\value{
List with:
\describe{
\item{library_data_raw}{Tibble with RAW spectra + property + cluster_id column}
\item{gmm_model}{Trained mclust model (for assigning unknowns)}
\item{pca_model}{PCA model (for projecting unknowns)}
\item{n_clusters}{Integer, optimal K selected}
\item{cluster_sizes}{Integer vector, samples per cluster}
\item{property}{Character, property name}
}
}
\description{
High-level orchestration functions that integrate library data loading, clustering,
and preparation for training. Connects the library-data, library-clustering, and
library-train modules into complete workflows.

Complete pipeline: load OSSL → preprocess for clustering → PCA → GMM clustering
→ add cluster assignments to RAW data. Returns everything needed for training
cluster-specific models.
}
\details{
This module provides the end-to-end pipeline for library-based prediction,
handling the critical architectural detail: clustering uses preprocessed data
(SNV for stability) while training uses raw data (for config-specific preprocessing).

\strong{Critical Architecture:}
\itemize{
\item Clustering: Uses SNV-preprocessed data for stable assignments
\item Training: Uses RAW data so build_recipe can apply config-specific preprocessing
\item Cluster assignments: Computed on preprocessed, joined to raw
}

\strong{Memory:} Keeps raw data (~67MB) for training flexibility. Discards preprocessed
data after clustering (only needed once).
}
\examples{
\dontrun{
library_result <- horizons:::prepare_library_for_training("clay", max_samples = 1000)
# Now train models on each cluster using raw data
}

}
\keyword{Data}
\keyword{Library}
\keyword{Prepare}
\keyword{Training}
\keyword{for}
\keyword{internal}
