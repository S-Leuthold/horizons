% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/inputs-create.R
\name{create_dataset}
\alias{create_dataset}
\title{Create Dataset for Modeling}
\usage{
create_dataset(
  spectra_data,
  response_data,
  response_variables = NULL,
  id_column = "Sample_ID",
  parse_ids = FALSE,
  id_format = NULL,
  id_delimiter = "_",
  aggregate_by = NULL,
  join_by = NULL,
  include_coords = TRUE,
  coord_columns = NULL,
  join_type = "inner",
  drop_na = TRUE,
  verbose = TRUE
)
}
\arguments{
\item{spectra_data}{Tibble. Preprocessed spectral data from preprocess_spectra()}

\item{response_data}{Character path or data.frame. Response variables with Sample_ID}

\item{response_variables}{Character vector. Which response columns to keep (NULL = all)}

\item{id_column}{Character. Column containing IDs to parse or join on. Default: "Sample_ID"}

\item{parse_ids}{Logical. Parse complex Sample_IDs into components? Default: FALSE}

\item{id_format}{Character. Format string like "project_sampleid_fraction_scan"}

\item{id_delimiter}{Character. Delimiter in IDs. Default: "_"}

\item{aggregate_by}{Character vector. Which parsed columns define unique samples for averaging.
Default: NULL (uses all parsed columns except 'scan' if present)}

\item{join_by}{Character vector. Column(s) to join with response data.
Default: NULL (auto-determined from aggregate_by or id_column)}

\item{include_coords}{Logical. Include coordinate columns? Default: TRUE}

\item{coord_columns}{Character vector. Explicit coord column names (NULL = auto-detect)}

\item{join_type}{Character. Join strategy for combining spectra and response data.
Default: "inner" (recommended for modeling - only samples with both spectra and response).
\itemize{
\item \code{"inner"}: Keep only samples with both spectra AND response (safe for modeling)
\item \code{"left"}: Keep all spectra, even without response (creates NAs - may cause downstream failures)
\item \code{"right"}: Keep all response samples, even without spectra (creates NAs in predictors)
\item \code{"full"}: Keep everything (creates NAs - use only for data auditing, not modeling)
}
Note: Non-inner joins may introduce NA values that will cause model evaluation to fail
unless \code{drop_na = TRUE} or data is filtered manually.}

\item{drop_na}{Logical. Drop rows with NA in response variables? Default: TRUE}

\item{verbose}{Logical. Print progress messages. Default: TRUE}
}
\value{
A tibble containing the merged spectral and response data with:
\describe{
\item{Sample_ID}{Character. Primary sample identifier (post-aggregation)}
\item{<spectral_cols>}{Numeric columns containing averaged spectral data}
\item{<response_vars>}{Selected response variables from response_data}
\item{<coord_cols>}{Spatial coordinates (if include_coords = TRUE)}
\item{n_replicates}{Integer. Number of spectral replicates averaged (if applicable)}
\item{<parsed_cols>}{Additional columns from ID parsing (if parse_ids = TRUE)}
}
}
\description{
Combines preprocessed spectral data with response variables to create
a modeling-ready dataset. This function handles complex sample ID parsing,
replicate aggregation, and spatial coordinate management. It serves as the
final step in the data preparation pipeline before model evaluation.
}
\details{
The function provides flexible data integration with several key capabilities:
\itemize{
\item Intelligent ID parsing using customizable format strings
\item Automatic replicate detection and averaging of spectral data
\item Flexible joining strategies (inner, left, right, full)
\item Automatic coordinate column detection and inclusion
\item Comprehensive data validation and quality control
}

When \code{parse_ids = TRUE}, sample IDs are parsed according to the
\code{id_format} pattern. Common patterns include:
\itemize{
\item \code{"project_sampleid_fraction_scan"} for soil fractionation studies
\item \code{"site_plot_depth_replicate"} for field sampling designs
\item \code{"experiment_treatment_timepoint"} for time-series studies
}
}
\examples{
\dontrun{
# Basic dataset creation
dataset <- create_dataset(
  spectra_data = preprocessed_spectra,
  response_data = "soil_properties.csv",
  response_variables = c("SOC", "clay", "pH")
)

# Advanced: ID parsing and coordinate inclusion
dataset <- create_dataset(
  spectra_data = spectra,
  response_data = response_df,
  parse_ids = TRUE,
  id_format = "site_plot_depth_rep",
  aggregate_by = c("site", "plot", "depth"),
  include_coords = TRUE,
  coord_columns = c("latitude", "longitude")
)
}

}
\seealso{
\code{\link{preprocess_spectra}} for spectral preprocessing,
\code{\link{create_configs}} for model configuration setup,
\code{\link{finalize_dataset}} for outlier detection

Other inputs: 
\code{\link{create_configs}()},
\code{\link{finalize_dataset}()},
\code{\link{preprocess_spectra}()},
\code{\link{read_spectra}()}
}
\concept{inputs}
\keyword{data-integration}
\keyword{spectroscopy}
